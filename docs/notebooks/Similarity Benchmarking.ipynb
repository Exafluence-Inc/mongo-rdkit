{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search Benchmarking\n",
    "\n",
    "These benchmarks were originally run on an early 2015 MacBook Pro with a 2.7 GHz dual-core i5 processor and 8GB of memory. \n",
    "\n",
    "They make use of a ChEMBL_27 dataset. \n",
    "## Setup Work\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mongordkit\n",
    "import time\n",
    "import pymongo\n",
    "import rdkit\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import sys\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from statistics import mean, median\n",
    "import mongomock\n",
    "from rdkit.Chem import AllChem\n",
    "from mongordkit.Database import write\n",
    "from mongordkit.Search import similarity\n",
    "from mongordkit import Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Setup\n",
    "Here we set up a database called `test` that will hold our molecules. We will construct a collection called `molecules_100K` to hold the first 100,000 molecules in the ChEMBL_27 dataset and a collection called `molecules_1M` to hold the first 1,000,000 molecules in the ChEMBL_27 dataset. If you have already run benchmarks from `mongo-rdkit` on your local MongoDB instance, these should have been set up already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client that will connect to the database.\n",
    "client = pymongo.MongoClient()\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, write the first 100,000 compounds to molecules_100K.\n",
    "if db.molecules_100K.count_documents({}) != 100000:\n",
    "    write.WriteFromSDF(db.molecules_100K, '../../../chembl_27.sdf', chunk_size=1000, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, write the first 1,000,000 compounds to molecules_1M.\n",
    "if db.molecules_1M.count_documents({}) != 1000000:\n",
    "    write.writeFromSDF(db.molecules_1M, '../../../chembl_27.sdf', chunk_size=1000, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ensure that there are actually 100,000 and 1M documents in these collections, respectively.\n",
    "print(f\"In molecules_100K: {db.molecules_100K.count_documents({})} documents\")\n",
    "print(f\"In molecules_1M: {db.molecules_1M.count_documents({})} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we have to prepare the database for search by adding in fingerprints and hash collections.\n",
    "Search.PrepareForSearch(db, db.molecules_100K, db.molecules_100KCt, db.molecules_100KPm)\n",
    "Search.PrepareForSearch(db, db.molecules_1M, db.molecules_1MCt, db.molecules_1MPm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Set Setup\n",
    "To benchmark, we'll use the first 200 compounds in ChEMBL. Let's get an rdmol for each of these and write them into a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_200 = []\n",
    "for rdmol in Chem.ForwardMolSupplier('../../data/test_data/first_200.props.sdf'): \n",
    "    first_200.append(rdmol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search each compound five times against the target database, taking the mean value as representative of that molecule. We'll then take the median and mean for all 200 compounds, repeating the entire process for thresholds 0.7, 0.75, 0.8, 0.85, and 0.9. \n",
    "\n",
    "We will benchmark both the `SimSearchAggregate` and `SimSearchLSH` methods, keeping in mind that the LSH method does not return exact results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "repetitions = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SimSearchAggregate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 100,000 molecules in ChEMBL. \n",
    "aggregate_means_100K = []\n",
    "aggregate_medians_100K = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchAggregate(rdmol, db.molecules_100K, db.molecules_100KCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    aggregate_means_100K.append([t, mean(query_times)])\n",
    "    aggregate_medians_100K.append([t, median(query_times)])\n",
    "\n",
    "print(f\"Aggregate means: {aggregate_means_100K}\")\n",
    "print(f\"Aggregate medians: {aggregate_medians_100K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we take a look at the 1M molecule dataset, let's graph these times to get a better idea of how similarity search increases in time required with lowered similarity thresholds: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [v[0] for v in aggregate_medians_100K]\n",
    "y_list = [v[1] for v in aggregate_medians_100K]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchAggregate medians / 100K dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the equivalent benchmarks against a million-molecule dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 1M molecules in ChEMBL. \n",
    "aggregate_means_1M = []\n",
    "aggregate_medians_1M = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchAggregate(rdmol, db.molecules_1M, db.molecules_1MCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    aggregate_means_1M.append([t, mean(query_times)])\n",
    "    aggregate_medians_1M.append([t, median(query_times)])\n",
    "\n",
    "print(f\"Aggregate means: {aggregate_means_1M}\")\n",
    "print(f\"Aggregate medians: {aggregate_medians_1M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [v[0] for v in aggregate_medians_1M]\n",
    "y_list = [v[1] for v in aggregate_medians_1M]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchAggregate medians / 1M dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SimSearchLSH`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will benchmark speed for LSH in the same way as we did for normal similarity search. As noted by the original ChEMBL authors of this approach, however, LSH also introduces an element of inaccuracy. Thus, we will also include a section on comparing results of `SimSearchAggregate` and `SimSearchLSH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 100,000 molecules in ChEMBL. \n",
    "LSH_means_100K = []\n",
    "LSH_medians_100K = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchLSH(rdmol, db, db.molecules_100K, \n",
    "                                        db.molecules_100KP, db.molecules_100KCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    LSH_means_100K.append([t, mean(query_times)])\n",
    "    LSH_medians_100K.append([t, median(query_times)])\n",
    "\n",
    "print(f\"LSH means: {LSH_means_100K}\")\n",
    "print(f\"LSH medians: {LSH_medians_100K}\")\n",
    "\n",
    "x_list = [v[0] for v in LSH_medians_100K]\n",
    "y_list = [v[1] for v in LSH_medians_100K]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchLSH medians / 100K dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 100,000 molecules in ChEMBL. \n",
    "LSH_means_1M = []\n",
    "LSH_medians_1M = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchLSH(rdmol, db, db.molecules_1M, \n",
    "                                        db.molecules_1MP, db.molecules_1MCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    LSH_means_1M.append([t, mean(query_times)])\n",
    "    LSH_medians_1M.append([t, median(query_times)])\n",
    "\n",
    "print(f\"LSH means: {LSH_means_1M}\")\n",
    "print(f\"LSH medians: {LSH_medians_1M}\")\n",
    "\n",
    "x_list = [v[0] for v in LSH_medians_1M]\n",
    "y_list = [v[1] for v in LSH_medians_1M]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchLSH medians / 1M dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare accuracy, we will use the approach written about in the ChEMBL blog post: finding the symmetric set difference between the two sets of results as a percentage of the size of the union of the two result sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring accuracy for similarity threshold {t}...\")\n",
    "    nmols_w_discrepancies = 0\n",
    "    discrepancies_per_mol = []\n",
    "    discrepancy_percent_per_mol = []\n",
    "    for rdmol in first_200:\n",
    "        sim_lsh = similarity.SimSearchLSH(rdmol, db, db.molecules_100K, \n",
    "                                          db.molecules_100KP, db.molecules_100KCt, threshold=t)\n",
    "        sim_agg = similarity.SimSearchAggregate(rdmol, db.molecules_100K, db.molecules_100KCt, threshold=t)\n",
    "        if sim_lsh: \n",
    "            set_lsh = set(result[1] for result in sim_lsh)\n",
    "        else:\n",
    "            set_lsh = set()\n",
    "        if sim_agg: \n",
    "            set_agg = set(result[1] for result in sim_agg)\n",
    "        else: \n",
    "            set_agg = set()\n",
    "        sym_set_diff = (set_lsh ^ set_agg)\n",
    "        discrepancies = len(sym_set_diff)\n",
    "        total = len(set_lsh | set_agg)\n",
    "        if discrepancies:\n",
    "            nmols_w_discrepancies += 1\n",
    "            discrepancies_per_mol.append(discrepancies)\n",
    "            discrepancy_percent_per_mol.append(discrepancies / total * 100)\n",
    "    results.append([t, f'nmols_w_discrepancies: {nmols_w_discrepancies}', \n",
    "                    np.mean(discrepancies_per_mol), np.mean(discrepancy_percent_per_mol)])\n",
    "print(results)\n",
    "x_list = [v[0] for v in results]\n",
    "y_list = [v[3] for v in results]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('discrepancy percent per molecule')\n",
    "plt.title('LSH Accuracy / 100K dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "These times are already very reasonable for a similarity search. However, it is worth noting that these benchmarks were run on a local MongoDB instance, effectively making no distinction between the client and the server. A MongoDB instance that has more horizontal scaling could benefit greatly from the aggregation pipeline, thus speeding search even further. \n",
    "\n",
    "The time complexity also increases greatly with decreasing Tanimoto thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_rdkit_beta",
   "language": "python",
   "name": "py37_rdkit_beta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
