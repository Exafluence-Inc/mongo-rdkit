{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search Benchmarking\n",
    "\n",
    "These benchmarks were originally run on an early 2015 MacBook Pro with a 2.7 GHz dual-core i5 processor and 8GB of memory. \n",
    "\n",
    "They make use of a ChEMBL_27 dataset. \n",
    "## Setup Work\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mongordkit\n",
    "import time\n",
    "import pymongo\n",
    "import rdkit\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import sys\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from statistics import mean, median\n",
    "import mongomock\n",
    "from rdkit.Chem import AllChem\n",
    "from mongordkit.Database import write\n",
    "from mongordkit.Search import similarity\n",
    "from mongordkit import Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Setup\n",
    "Here we set up a database called `test` that will hold our molecules. We will construct a collection called `molecules_100K` to hold the first 100,000 molecules in the ChEMBL_27 dataset and a collection called `molecules_1M` to hold the first 1,000,000 molecules in the ChEMBL_27 dataset. If you have already run benchmarks from `mongo-rdkit` on your local MongoDB instance, these should have been set up already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client that will connect to the database.\n",
    "client = pymongo.MongoClient()\n",
    "db = client.test\n",
    "chembl = '../../../chembl_27.sdf'\n",
    "\n",
    "# Disable rdkit warnings\n",
    "rdkit.RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, write the first 100,000 compounds to molecules_100K.\n",
    "if db.molecules_100K.count_documents({}) != 100000:\n",
    "    write.WriteFromSDF(db.molecules_100K, chembl, chunk_size=1000, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, write the first 1,000,000 compounds to molecules_1M.\n",
    "if db.molecules_1M.count_documents({}) != 1000000:\n",
    "    write.writeFromSDF(db.molecules_1M, chembl, chunk_size=1000, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In molecules_100K: 100000 documents\n",
      "In molecules_1M: 629512 documents\n"
     ]
    }
   ],
   "source": [
    "# Let's ensure that there are actually 100,000 and 1M documents in these collections, respectively.\n",
    "print(f\"In molecules_100K: {db.molecules_100K.count_documents({})} documents\")\n",
    "print(f\"In molecules_1M: {db.molecules_1M.count_documents({})} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing database and collections for search...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-085ae5f1e023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Next, we have to prepare the database for search by adding in fingerprints and hash collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrepareForSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecules_100K\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecules_100KCt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecules_100KPm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mSearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrepareForSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecules_1M\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecules_1MCt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecules_1MPm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mongo-rdkit/mongordkit/Search/__init__.py\u001b[0m in \u001b[0;36mPrepareForSearch\u001b[0;34m(db, mol_collection, count_collection, perm_collection)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPrepareForSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preparing database and collections for search...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mAddPatternFingerprints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mAddMorganFingerprints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddRandPermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mongo-rdkit/mongordkit/Search/substructure.py\u001b[0m in \u001b[0;36mAddPatternFingerprints\u001b[0;34m(mol_collection)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbit_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPatternFingerprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetOnBits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbit_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mmol_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmoldoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'$set'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'fingerprints.pattern_fp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'bits'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbit_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37_rdkit_beta/lib/python3.7/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36mupdate_one\u001b[0;34m(self, filter, update, upsert, bypass_document_validation, collation, array_filters, session)\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0mbypass_doc_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbypass_document_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mcollation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 session=session),\n\u001b[0m\u001b[1;32m   1004\u001b[0m             write_concern.acknowledged)\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37_rdkit_beta/lib/python3.7/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m_update_retryable\u001b[0;34m(self, criteria, document, upsert, check_keys, multi, manipulate, write_concern, op_id, ordered, bypass_doc_val, collation, array_filters, session)\u001b[0m\n\u001b[1;32m    854\u001b[0m         return self.__database.client._retryable_write(\n\u001b[1;32m    855\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mwrite_concern\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macknowledged\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             _update, session)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def replace_one(self, filter, replacement, upsert=False,\n",
      "\u001b[0;32m~/anaconda3/envs/py37_rdkit_beta/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_write\u001b[0;34m(self, retryable, func, session)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;34m\"\"\"Internal retryable write helper.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_with_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretryable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reset_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37_rdkit_beta/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retry_with_session\u001b[0;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[1;32m   1375\u001b[0m                     \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m                     server.description.retryable_writes_supported)\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mretryable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupports_session\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mis_retrying\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37_rdkit_beta/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37_rdkit_beta/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_get_socket\u001b[0;34m(self, server, session, exhaust)\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 self, server.description.address, session) as err_handler:\n\u001b[1;32m   1221\u001b[0m             with server.get_socket(\n\u001b[0;32m-> 1222\u001b[0;31m                     self.__all_credentials, checkout=exhaust) as sock_info:\n\u001b[0m\u001b[1;32m   1223\u001b[0m                 \u001b[0merr_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontribute_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                 if (self._encrypter and\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Next, we have to prepare the database for search by adding in fingerprints and hash collections.\n",
    "Search.PrepareForSearch(db, db.molecules_100K, db.molecules_100KCt, db.molecules_100KPm)\n",
    "Search.PrepareForSearch(db, db.molecules_1M, db.molecules_1MCt, db.molecules_1MPm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Set Setup\n",
    "To benchmark, we'll use the first 200 compounds in ChEMBL. Let's get an rdmol for each of these and write them into a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_200 = []\n",
    "for rdmol in Chem.ForwardMolSupplier('../../data/test_data/first_200.props.sdf'): \n",
    "    first_200.append(rdmol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search each compound five times against the target database, taking the mean value as representative of that molecule. We'll then take the median and mean for all 200 compounds, repeating the entire process for thresholds 0.7, 0.75, 0.8, 0.85, and 0.9. \n",
    "\n",
    "We will benchmark both the `SimSearchAggregate` and `SimSearchLSH` methods, keeping in mind that the LSH method does not return exact results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "repetitions = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SimSearchAggregate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 100,000 molecules in ChEMBL. \n",
    "aggregate_means_100K = []\n",
    "aggregate_medians_100K = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchAggregate(rdmol, db.molecules_100K, db.molecules_100KCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    aggregate_means_100K.append([t, mean(query_times)])\n",
    "    aggregate_medians_100K.append([t, median(query_times)])\n",
    "\n",
    "print(f\"Aggregate means: {aggregate_means_100K}\")\n",
    "print(f\"Aggregate medians: {aggregate_medians_100K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we take a look at the 1M molecule dataset, let's graph these times to get a better idea of how similarity search increases in time required with lowered similarity thresholds: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [v[0] for v in aggregate_medians_100K]\n",
    "y_list = [v[1] for v in aggregate_medians_100K]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchAggregate medians / 100K dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the equivalent benchmarks against a million-molecule dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 1M molecules in ChEMBL. \n",
    "aggregate_means_1M = []\n",
    "aggregate_medians_1M = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchAggregate(rdmol, db.molecules_1M, db.molecules_1MCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    aggregate_means_1M.append([t, mean(query_times)])\n",
    "    aggregate_medians_1M.append([t, median(query_times)])\n",
    "\n",
    "print(f\"Aggregate means: {aggregate_means_1M}\")\n",
    "print(f\"Aggregate medians: {aggregate_medians_1M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [v[0] for v in aggregate_medians_1M]\n",
    "y_list = [v[1] for v in aggregate_medians_1M]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchAggregate medians / 1M dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SimSearchLSH`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will benchmark speed for LSH in the same way as we did for normal similarity search. As noted by the original ChEMBL authors of this approach, however, LSH also introduces an element of inaccuracy. Thus, we will also include a section on comparing results of `SimSearchAggregate` and `SimSearchLSH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 100,000 molecules in ChEMBL. \n",
    "LSH_means_100K = []\n",
    "LSH_medians_100K = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchLSH(rdmol, db, db.molecules_100K, \n",
    "                                        db.molecules_100KP, db.molecules_100KCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    LSH_means_100K.append([t, mean(query_times)])\n",
    "    LSH_medians_100K.append([t, median(query_times)])\n",
    "\n",
    "print(f\"LSH means: {LSH_means_100K}\")\n",
    "print(f\"LSH medians: {LSH_medians_100K}\")\n",
    "\n",
    "x_list = [v[0] for v in LSH_medians_100K]\n",
    "y_list = [v[1] for v in LSH_medians_100K]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchLSH medians / 100K dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark against the first 100,000 molecules in ChEMBL. \n",
    "LSH_means_1M = []\n",
    "LSH_medians_1M = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring performance for similarity threshold {t}...\")\n",
    "    query_times = []\n",
    "    for rdmol in first_200:\n",
    "        temp_times = []\n",
    "        for r in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = similarity.SimSearchLSH(rdmol, db, db.molecules_1M, \n",
    "                                        db.molecules_1MP, db.molecules_1MCt, threshold=t)\n",
    "            end = time.time()\n",
    "            temp_times.append(end - start)\n",
    "        query_times.append(mean(temp_times))\n",
    "    LSH_means_1M.append([t, mean(query_times)])\n",
    "    LSH_medians_1M.append([t, median(query_times)])\n",
    "\n",
    "print(f\"LSH means: {LSH_means_1M}\")\n",
    "print(f\"LSH medians: {LSH_medians_1M}\")\n",
    "\n",
    "x_list = [v[0] for v in LSH_medians_1M]\n",
    "y_list = [v[1] for v in LSH_medians_1M]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('SimSearchLSH medians / 1M dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare accuracy, we will use the approach written about in the ChEMBL blog post: finding the symmetric set difference between the two sets of results as a percentage of the size of the union of the two result sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for t in thresholds: \n",
    "    print(f\"Measuring accuracy for similarity threshold {t}...\")\n",
    "    nmols_w_discrepancies = 0\n",
    "    discrepancies_per_mol = []\n",
    "    discrepancy_percent_per_mol = []\n",
    "    for rdmol in first_200:\n",
    "        sim_lsh = similarity.SimSearchLSH(rdmol, db, db.molecules_100K, \n",
    "                                          db.molecules_100KP, db.molecules_100KCt, threshold=t)\n",
    "        sim_agg = similarity.SimSearchAggregate(rdmol, db.molecules_100K, db.molecules_100KCt, threshold=t)\n",
    "        if sim_lsh: \n",
    "            set_lsh = set(result[1] for result in sim_lsh)\n",
    "        else:\n",
    "            set_lsh = set()\n",
    "        if sim_agg: \n",
    "            set_agg = set(result[1] for result in sim_agg)\n",
    "        else: \n",
    "            set_agg = set()\n",
    "        sym_set_diff = (set_lsh ^ set_agg)\n",
    "        discrepancies = len(sym_set_diff)\n",
    "        total = len(set_lsh | set_agg)\n",
    "        if discrepancies:\n",
    "            nmols_w_discrepancies += 1\n",
    "            discrepancies_per_mol.append(discrepancies)\n",
    "            discrepancy_percent_per_mol.append(discrepancies / total * 100)\n",
    "    results.append([t, f'nmols_w_discrepancies: {nmols_w_discrepancies}', \n",
    "                    np.mean(discrepancies_per_mol), np.mean(discrepancy_percent_per_mol)])\n",
    "print(results)\n",
    "x_list = [v[0] for v in results]\n",
    "y_list = [v[3] for v in results]\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('discrepancy percent per molecule')\n",
    "plt.title('LSH Accuracy / 100K dataset')\n",
    "plt.plot(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "These times are already very reasonable for a similarity search. However, it is worth noting that these benchmarks were run on a local MongoDB instance, effectively making no distinction between the client and the server. A MongoDB instance that has more horizontal scaling could benefit greatly from the aggregation pipeline, thus speeding search even further. \n",
    "\n",
    "The time complexity also increases greatly with decreasing Tanimoto thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_rdkit_beta",
   "language": "python",
   "name": "py37_rdkit_beta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
