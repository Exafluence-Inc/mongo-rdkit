{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substructure Search Benchmarking\n",
    "\n",
    "These benchmarks were originally run on an early 2015 MacBook Pro with a 2.7 GHz dual-core i5 processor and 8GB of memory. \n",
    "\n",
    "In addition to the dependencies listed below, they make use of three sets of fragments and patterns you can find in `mongordkit/data`. All of the large chemical databases that we search against are constructed from ChEMBL_27. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Work\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random, gzip, time, mongordkit, pymongo, rdkit, matplotlib\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import rdBase\n",
    "from rdkit import DataStructs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import sys\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from mongordkit.Database import write\n",
    "from mongordkit.Search import similarity\n",
    "from mongordkit.Search import substructure\n",
    "from mongordkit import Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Setup\n",
    "Here we set up a database called `test` that will hold our molecules. We will construct a collection called `molecules_100K` to hold the first 100,000 molecules in the ChEMBL_27 dataset and a collection called `molecules_1M` to hold the first 1,000,000 molecules in the ChEMBL_27 dataset. If you have already run benchmarks from `mongo-rdkit` on your local MongoDB instance, these should have been set up already."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Initialize the client that will connect to the database.\n",
    "client = pymongo.MongoClient()\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating mongodb collection with compounds from SDF...\n",
      "100000 molecules successfully imported\n",
      "1 duplicates skipped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If necessary, write the first 100,000 compounds to molecules_100K.\n",
    "if db.molecules_100K.count_documents({}) != 100000:\n",
    "    write.WriteFromSDF(db.molecules_100K, '../../../chembl_27.sdf', chunk_size=1000, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating mongodb collection with compounds from SDF...\n"
     ]
    }
   ],
   "source": [
    "# If necessary, write the first 1,000,000 compounds to molecules_1M.\n",
    "if db.molecules_1M.count_documents({}) != 1000000:\n",
    "    write.WriteFromSDF(db.molecules_1M, '../../../chembl_27.sdf', chunk_size=1000, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In molecules_100K: 100000 documents\n",
      "In molecules_1M: 180512 documents\n"
     ]
    }
   ],
   "source": [
    "# Let's ensure that there are actually 100,000 and 1M documents in these collections, respectively.\n",
    "print(f\"In molecules_100K: {db.molecules_100K.count_documents({})} documents\")\n",
    "print(f\"In molecules_1M: {db.molecules_1M.count_documents({})} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we have to prepare all of the documents in our collections for search by adding in fingerprints.\n",
    "substructure.AddPatternFingerprints(db.molecules_100K)\n",
    "substructure.AddPatternFingerprints(db.molecules_1M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Set Setup\n",
    "For our queries, we'll use three sets of patterns identified by Greg Landrum in one of his [blog posts](http://rdkit.blogspot.com/2013/11/fingerprint-based-substructure.html) on substructure searching and discussed in this [mailing list](http://www.mail-archive.com/rdkit-discuss@lists.sourceforge.net/msg02066.html) and this [presentation](http://www.hinxton.wellcome.ac.uk/advancedcourses/MIOSS%20Greg%20Landrum.pdf). They are: \n",
    "- Fragments: 500 diverse molecules taken from the ZINC Fragments set\n",
    "- Leads: 500 diverse molecules taken from the ZINC Lead-like set\n",
    "- Pieces: 823 pieces of molecules obtained by doing a BRICS fragmentation of some molecules from the pubchem screening set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../../data/zinc.frags.500.q.smi')\n",
    "fragments = [Chem.MolFromSmiles(line.split()[0]) for line in f]\n",
    "f.close()\n",
    "\n",
    "f = open('../../data/zinc.leads.500.q.smi')\n",
    "leads = [Chem.MolFromSmiles(line.split()[0]) for line in f]\n",
    "f.close()\n",
    "\n",
    "f = open('../../data/fragqueries.q.txt')\n",
    "pieces = [Chem.MolFromSmiles(line) for line in f]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "### Naive Substructure Search\n",
    "`substructure.SubSearchNaive` is a search that simply loops through the dataset and checks for a substructure match on each molecule. This method is not directly benchmarked here because searching through a single molecule takes upward of 5 seconds; this means that it is far too slow to feel directly interactive.\n",
    "### Substructure Search with Fingerprint Screening\n",
    "Instead, we will benchmark the standard `SubSearch`, which makes use of fingerprint screening to dramatically increase efficiency. For each of our query sets, we will search all of their elements against `molecules_100K` and `molecules_1M`, then return the median and mean query times in seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_query_set(query_set, dataset):\n",
    "    results = []\n",
    "    for pattern in query_set:\n",
    "        start = time.time()\n",
    "        substructure.SubSearch(pattern, dataset)\n",
    "        end = time.time()\n",
    "        results.append(end - start)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fragments</th>\n",
       "      <td>0.062740</td>\n",
       "      <td>0.062074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leads</th>\n",
       "      <td>0.062592</td>\n",
       "      <td>0.062289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces</th>\n",
       "      <td>0.062739</td>\n",
       "      <td>0.061950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean    median\n",
       "fragments  0.062740  0.062074\n",
       "leads      0.062592  0.062289\n",
       "pieces     0.062739  0.061950"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark for search of all three query sets against 100K and 1M.\n",
    "# This should take around five minutes; these calls commented out if necessary.\n",
    "frag_times_100K = benchmark_query_set(fragments, db.molecules_100K)\n",
    "lead_times_100K = benchmark_query_set(leads, db.molecules_100K)\n",
    "pieces_times_100K = benchmark_query_set(pieces, db.molecules_100K)\n",
    "\n",
    "results = [frag_times_100K, lead_times_100K, pieces_times_100K]\n",
    "means_100K = [np.mean(times) for times in results]\n",
    "medians_100K = [np.median(times) for times in results]\n",
    "\n",
    "data = {'mean (100K)': means, 'median (100K)': medians}\n",
    "df = pd.DataFrame(data, index =['fragments', 'leads', 'pieces']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark for search of all three query sets against 1M. \n",
    "# This should take around five minutes; these calls can be commented out if necessary.\n",
    "frag_times_1M = benchmark_query_set(fragments, db.molecules_1M)\n",
    "lead_times_1M = benchmark_query_set(leads, db.molecules_1M)\n",
    "pieces_times_1M = benchmark_query_set(pieces, db.molecules_1M)\n",
    "\n",
    "results = [frag_times_1M, lead_times_1M, pieces_times_1M]\n",
    "means_1M = [np.mean(times) for times in results]\n",
    "medians_1M = [np.median(times) for times in results]\n",
    "\n",
    "data = {'mean (1M)': means, 'median (1M)': medians}\n",
    "df = pd.DataFrame(data, index =['fragments', 'leads', 'pieces']) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "A median search time of less than 70ms indicates decent performance, certainly fast enough to have interactive search performance on large datasets with single molecules (the traditional UI benchmark for instant feedback being 100ms). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Size\n",
    "Now we are also interested in learning how this substructure search scales according to the size of the dataset. In order to do so, we will conduct the searches with the same query set against datasets of increasing size, from 1000 - 10,000 molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_rdkit_beta",
   "language": "python",
   "name": "py37_rdkit_beta"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
